{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "LeNet_HyperTuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install optuna"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8yQiKcze3GJ",
    "outputId": "fdae5b09-be42-4d68-cdca-555ba260a5ad",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "\u001B[K     |████████████████████████████████| 308 kB 7.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
      "\u001B[K     |████████████████████████████████| 210 kB 68.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "\u001B[K     |████████████████████████████████| 81 kB 12.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.35)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.8)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
      "\u001B[K     |████████████████████████████████| 78 kB 9.4 MB/s \n",
      "\u001B[?25hCollecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "\u001B[K     |████████████████████████████████| 49 kB 8.3 MB/s \n",
      "\u001B[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
      "\u001B[K     |████████████████████████████████| 146 kB 65.9 MB/s \n",
      "\u001B[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
      "\u001B[K     |████████████████████████████████| 113 kB 74.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=1a2f4e61f0565fae88a72ebb10360b4a84e7a160e3d962d2593bbd17fa2f082c\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s8eyh7QKerwq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def create_dataloader(batch_size=64, valid_size=0.2, DIR='D:/datasets/'):\n",
    "    # convert data to torch.FloatTensor\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # choose the training and test datasets\n",
    "    train_data = datasets.FashionMNIST(root=DIR,\n",
    "                                train=True,\n",
    "                                download=True,\n",
    "                                transform=transform)\n",
    "    test_data = datasets.FashionMNIST(root=DIR,\n",
    "                               train=False,\n",
    "                               download=False,\n",
    "                               transform=transform)\n",
    "\n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # load training data in batches\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=train_sampler,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    # load validation data in batches\n",
    "    valid_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=valid_sampler,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    # load test data in batches\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(target.view_as(pred)).sum().item() / args.batch_size\n",
    "        train_accuracy += acc\n",
    "        loss = args.criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), acc,\n",
    "            ))\n",
    "\n",
    "\n",
    "def validate(args, model, device, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += args.criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_acc += pred.eq(target.view_as(pred)).sum().item() / args.batch_size\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc /= len(val_loader)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1024, metavar='N',\n",
    "                        help='input batch size for testing (default: 1024)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=500, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--criterion', default=nn.CrossEntropyLoss(),\n",
    "                        help='loss function of training')\n",
    "    parser.add_argument('--model-path', type=str, default='./models/LeNet_tune.pt',\n",
    "                        help='directory to save model')\n",
    "    parser.add_argument('--optimizer-name', type=str, default='Adam',\n",
    "                        help='name of the optimier')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "args = get_args()\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    model = LeNet().to(device)\n",
    "\n",
    "    optimizer_name = args.optimizer_name\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader, val_loader, _ = create_dataloader()\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        _, val_acc = validate(args, model, device, val_loader)\n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_acc"
   ],
   "metadata": {
    "id": "VOs73Mhue0Y7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def create_dataloader(batch_size=64, valid_size=0.2, DIR='D:/datasets/'):\n",
    "    # convert data to torch.FloatTensor\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # choose the training and test datasets\n",
    "    train_data = datasets.FashionMNIST(root=DIR,\n",
    "                                train=True,\n",
    "                                download=False,\n",
    "                                transform=transform)\n",
    "    test_data = datasets.FashionMNIST(root=DIR,\n",
    "                               train=False,\n",
    "                               download=False,\n",
    "                               transform=transform)\n",
    "\n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # load training data in batches\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=train_sampler,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    # load validation data in batches\n",
    "    valid_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=valid_sampler,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    # load test data in batches\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(target.view_as(pred)).sum().item() / args.batch_size\n",
    "        train_accuracy += acc\n",
    "        loss = args.criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), acc,\n",
    "            ))\n",
    "\n",
    "\n",
    "def validate(args, model, device, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += args.criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_acc += pred.eq(target.view_as(pred)).sum().item() / args.batch_size\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc /= len(val_loader)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1024, metavar='N',\n",
    "                        help='input batch size for testing (default: 1024)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=500, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--criterion', default=nn.CrossEntropyLoss(),\n",
    "                        help='loss function of training')\n",
    "    parser.add_argument('--model-path', type=str, default='./models/LeNet_tune.pt',\n",
    "                        help='directory to save model')\n",
    "    parser.add_argument('--optimizer-name', type=str, default='Adam',\n",
    "                        help='name of the optimier')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "args = get_args()\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print('Using ', device)\n",
    "\n",
    "    model = LeNet().to(device)\n",
    "\n",
    "    optimizer_name = args.optimizer_name\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    args.batch_size = batch_size\n",
    "    train_loader, val_loader, _ = create_dataloader(batch_size=args.batch_size)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        _, val_acc = validate(args, model, device, val_loader)\n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_acc"
   ],
   "metadata": {
    "id": "_MdlswDwEGTo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def create_dataloader(batch_size=64, valid_size=0.2, DIR='D:/datasets/'):\n",
    "    # convert data to torch.FloatTensor\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # choose the training and test datasets\n",
    "    train_data = datasets.FashionMNIST(root=DIR,\n",
    "                                train=True,\n",
    "                                download=False,\n",
    "                                transform=transform)\n",
    "    test_data = datasets.FashionMNIST(root=DIR,\n",
    "                               train=False,\n",
    "                               download=False,\n",
    "                               transform=transform)\n",
    "\n",
    "    # obtain training indices that will be used for validation\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # load training data in batches\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=train_sampler,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    # load validation data in batches\n",
    "    valid_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=valid_sampler,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    # load test data in batches\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(target.view_as(pred)).sum().item() / args.batch_size\n",
    "        train_accuracy += acc\n",
    "        loss = args.criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def validate(args, model, device, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += args.criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_acc += pred.eq(target.view_as(pred)).sum().item() / args.batch_size\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc /= len(val_loader)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1024, metavar='N',\n",
    "                        help='input batch size for testing (default: 1024)')\n",
    "    parser.add_argument('--epochs', type=int, default=5, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--criterion', default=nn.CrossEntropyLoss(),\n",
    "                        help='loss function of training')\n",
    "    parser.add_argument('--model-path', type=str, default='./models/LeNet_tune.pt',\n",
    "                        help='directory to save model')\n",
    "    parser.add_argument('--optimizer-name', type=str, default='Adam',\n",
    "                        help='name of the optimier')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "args = get_args()\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    model = LeNet().to(device)\n",
    "\n",
    "    optimizer_name = args.optimizer_name\n",
    "    init_lr = trial.suggest_float(\"init_lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=init_lr)\n",
    "\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.6, 1.0)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    args.batch_size = batch_size\n",
    "    train_loader, val_loader, _ = create_dataloader(batch_size=args.batch_size)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        _, val_acc = validate(args, model, device, val_loader)\n",
    "        print('epoch {} of {}: val_acc: {:.3f}'.format(epoch+1, args.epochs, val_acc))\n",
    "        scheduler.step()\n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_acc"
   ],
   "metadata": {
    "id": "Y-Ed4k9NFxnr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using ', device)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PINBv0cCswo",
    "outputId": "51c0f02f-06f7-494e-eb08-4e6275e72528",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:55:03,215]\u001B[0m A new study created in memory with name: no-name-f57fb6d4-67c0-4af6-bd4b-472bd3ac8337\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using  cuda\n",
      "epoch 1 of 5: val_acc: 0.862\n",
      "epoch 2 of 5: val_acc: 0.883\n",
      "epoch 3 of 5: val_acc: 0.891\n",
      "epoch 4 of 5: val_acc: 0.893\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:55:37,240]\u001B[0m Trial 0 finished with value: 0.9005984042553191 and parameters: {'init_lr': 0.0015675612393006848, 'gamma': 0.8632463261350161, 'batch_size': 64}. Best is trial 0 with value: 0.9005984042553191.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.901\n",
      "epoch 1 of 5: val_acc: 0.842\n",
      "epoch 2 of 5: val_acc: 0.865\n",
      "epoch 3 of 5: val_acc: 0.873\n",
      "epoch 4 of 5: val_acc: 0.876\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:56:04,751]\u001B[0m Trial 1 finished with value: 0.8769115691489362 and parameters: {'init_lr': 0.00017235698661844536, 'gamma': 0.6320971021747585, 'batch_size': 128}. Best is trial 0 with value: 0.9005984042553191.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.877\n",
      "epoch 1 of 5: val_acc: 0.810\n",
      "epoch 2 of 5: val_acc: 0.842\n",
      "epoch 3 of 5: val_acc: 0.853\n",
      "epoch 4 of 5: val_acc: 0.862\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:56:32,521]\u001B[0m Trial 2 finished with value: 0.8617021276595744 and parameters: {'init_lr': 0.00012640888333802916, 'gamma': 0.7889946232985741, 'batch_size': 128}. Best is trial 0 with value: 0.9005984042553191.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.862\n",
      "epoch 1 of 5: val_acc: 0.870\n",
      "epoch 2 of 5: val_acc: 0.888\n",
      "epoch 3 of 5: val_acc: 0.903\n",
      "epoch 4 of 5: val_acc: 0.904\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:57:43,437]\u001B[0m Trial 3 finished with value: 0.9073333333333333 and parameters: {'init_lr': 0.0022713543306523225, 'gamma': 0.7310585347535046, 'batch_size': 16}. Best is trial 3 with value: 0.9073333333333333.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.907\n",
      "epoch 1 of 5: val_acc: 0.678\n",
      "epoch 2 of 5: val_acc: 0.725\n",
      "epoch 3 of 5: val_acc: 0.745\n",
      "epoch 4 of 5: val_acc: 0.764\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:58:11,119]\u001B[0m Trial 4 finished with value: 0.7802526595744681 and parameters: {'init_lr': 1.3915223146639235e-05, 'gamma': 0.9914475009914437, 'batch_size': 128}. Best is trial 3 with value: 0.9073333333333333.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.780\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:58:25,120]\u001B[0m Trial 5 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.750\n",
      "epoch 1 of 5: val_acc: 0.885\n",
      "epoch 2 of 5: val_acc: 0.891\n",
      "epoch 3 of 5: val_acc: 0.902\n",
      "epoch 4 of 5: val_acc: 0.901\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:59:35,692]\u001B[0m Trial 6 finished with value: 0.90925 and parameters: {'init_lr': 0.0009958190182511953, 'gamma': 0.9108069436282582, 'batch_size': 16}. Best is trial 6 with value: 0.90925.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.909\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 03:59:49,856]\u001B[0m Trial 7 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.849\n",
      "epoch 1 of 5: val_acc: 0.859\n",
      "epoch 2 of 5: val_acc: 0.879\n",
      "epoch 3 of 5: val_acc: 0.885\n",
      "epoch 4 of 5: val_acc: 0.892\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:00:17,205]\u001B[0m Trial 8 finished with value: 0.8966090425531915 and parameters: {'init_lr': 0.0004220662538479327, 'gamma': 0.6897490044381996, 'batch_size': 128}. Best is trial 6 with value: 0.90925.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.897\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:00:26,391]\u001B[0m Trial 9 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.838\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:00:33,050]\u001B[0m Trial 10 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.795\n",
      "epoch 1 of 5: val_acc: 0.879\n",
      "epoch 2 of 5: val_acc: 0.889\n",
      "epoch 3 of 5: val_acc: 0.897\n",
      "epoch 4 of 5: val_acc: 0.903\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:01:43,651]\u001B[0m Trial 11 finished with value: 0.90325 and parameters: {'init_lr': 0.002891405053932895, 'gamma': 0.791706043903631, 'batch_size': 16}. Best is trial 6 with value: 0.90925.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.903\n",
      "epoch 1 of 5: val_acc: 0.872\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:02:11,746]\u001B[0m Trial 12 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 of 5: val_acc: 0.879\n",
      "epoch 1 of 5: val_acc: 0.882\n",
      "epoch 2 of 5: val_acc: 0.885\n",
      "epoch 3 of 5: val_acc: 0.905\n",
      "epoch 4 of 5: val_acc: 0.908\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:03:21,652]\u001B[0m Trial 13 finished with value: 0.9136666666666666 and parameters: {'init_lr': 0.0005805506600453946, 'gamma': 0.9299130064982555, 'batch_size': 16}. Best is trial 13 with value: 0.9136666666666666.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.914\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:03:30,745]\u001B[0m Trial 14 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.832\n",
      "epoch 1 of 5: val_acc: 0.883\n",
      "epoch 2 of 5: val_acc: 0.897\n",
      "epoch 3 of 5: val_acc: 0.899\n",
      "epoch 4 of 5: val_acc: 0.907\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:04:40,743]\u001B[0m Trial 15 finished with value: 0.9040833333333333 and parameters: {'init_lr': 0.0005218913501129159, 'gamma': 0.8379707182826234, 'batch_size': 16}. Best is trial 13 with value: 0.9136666666666666.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.904\n",
      "epoch 1 of 5: val_acc: 0.878\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:05:09,019]\u001B[0m Trial 16 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 of 5: val_acc: 0.883\n",
      "Study statistics: \n",
      "  Number of finished trials:  17\n",
      "  Number of pruned trials:  7\n",
      "  Number of complete trials:  10\n",
      "Best trial:\n",
      "  Value:  0.9136666666666666\n",
      "  Params: \n",
      "    init_lr: 0.0005805506600453946\n",
      "    gamma: 0.9299130064982555\n",
      "    batch_size: 16\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using ', device)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXELcx8VCuw4",
    "outputId": "2864107a-49b1-4d42-dc01-7e13abcc93d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:06:03,059]\u001B[0m A new study created in memory with name: no-name-3c2423ea-313b-4b2b-ae4b-fe5c834b284a\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using  cuda\n",
      "epoch 1 of 5: val_acc: 0.806\n",
      "epoch 2 of 5: val_acc: 0.840\n",
      "epoch 3 of 5: val_acc: 0.857\n",
      "epoch 4 of 5: val_acc: 0.864\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:06:30,575]\u001B[0m Trial 0 finished with value: 0.8686003989361702 and parameters: {'init_lr': 7.844292368759098e-05, 'gamma': 0.7793832683148582, 'batch_size': 128}. Best is trial 0 with value: 0.8686003989361702.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.869\n",
      "epoch 1 of 5: val_acc: 0.867\n",
      "epoch 2 of 5: val_acc: 0.891\n",
      "epoch 3 of 5: val_acc: 0.888\n",
      "epoch 4 of 5: val_acc: 0.895\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:07:04,338]\u001B[0m Trial 1 finished with value: 0.9031748670212766 and parameters: {'init_lr': 0.005537760222119039, 'gamma': 0.8160780692017976, 'batch_size': 64}. Best is trial 1 with value: 0.9031748670212766.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.903\n",
      "epoch 1 of 5: val_acc: 0.875\n",
      "epoch 2 of 5: val_acc: 0.886\n",
      "epoch 3 of 5: val_acc: 0.899\n",
      "epoch 4 of 5: val_acc: 0.901\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:07:31,842]\u001B[0m Trial 2 finished with value: 0.9053357712765957 and parameters: {'init_lr': 0.011992839317318791, 'gamma': 0.6355394493401878, 'batch_size': 128}. Best is trial 2 with value: 0.9053357712765957.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.905\n",
      "epoch 1 of 5: val_acc: 0.870\n",
      "epoch 2 of 5: val_acc: 0.884\n",
      "epoch 3 of 5: val_acc: 0.901\n",
      "epoch 4 of 5: val_acc: 0.904\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:07:59,719]\u001B[0m Trial 3 finished with value: 0.9103224734042553 and parameters: {'init_lr': 0.009707468231345402, 'gamma': 0.6330331359309136, 'batch_size': 128}. Best is trial 3 with value: 0.9103224734042553.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.910\n",
      "epoch 1 of 5: val_acc: 0.821\n",
      "epoch 2 of 5: val_acc: 0.855\n",
      "epoch 3 of 5: val_acc: 0.866\n",
      "epoch 4 of 5: val_acc: 0.872\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:08:45,537]\u001B[0m Trial 4 finished with value: 0.87575 and parameters: {'init_lr': 4.2152679808981527e-05, 'gamma': 0.8285488908770086, 'batch_size': 32}. Best is trial 3 with value: 0.9103224734042553.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.876\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:08:51,051]\u001B[0m Trial 5 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.845\n",
      "epoch 1 of 5: val_acc: 0.870\n",
      "epoch 2 of 5: val_acc: 0.892\n",
      "epoch 3 of 5: val_acc: 0.897\n",
      "epoch 4 of 5: val_acc: 0.902\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:09:18,557]\u001B[0m Trial 6 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.900\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:09:23,968]\u001B[0m Trial 7 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.772\n",
      "epoch 1 of 5: val_acc: 0.877\n",
      "epoch 2 of 5: val_acc: 0.891\n",
      "epoch 3 of 5: val_acc: 0.899\n",
      "epoch 4 of 5: val_acc: 0.912\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:10:09,674]\u001B[0m Trial 8 finished with value: 0.9135833333333333 and parameters: {'init_lr': 0.013716164454697791, 'gamma': 0.710050770582094, 'batch_size': 32}. Best is trial 8 with value: 0.9135833333333333.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.914\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:10:18,978]\u001B[0m Trial 9 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.858\n",
      "epoch 1 of 5: val_acc: 0.879\n",
      "epoch 2 of 5: val_acc: 0.896\n",
      "epoch 3 of 5: val_acc: 0.897\n",
      "epoch 4 of 5: val_acc: 0.908\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:11:29,227]\u001B[0m Trial 10 finished with value: 0.9093333333333333 and parameters: {'init_lr': 0.0005984846940131705, 'gamma': 0.6989958905749444, 'batch_size': 16}. Best is trial 8 with value: 0.9135833333333333.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.909\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:11:38,541]\u001B[0m Trial 11 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.764\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:11:45,237]\u001B[0m Trial 12 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.854\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:11:59,242]\u001B[0m Trial 13 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.830\n",
      "epoch 1 of 5: val_acc: 0.879\n",
      "epoch 2 of 5: val_acc: 0.887\n",
      "epoch 3 of 5: val_acc: 0.903\n",
      "epoch 4 of 5: val_acc: 0.908\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:12:44,846]\u001B[0m Trial 14 finished with value: 0.9089166666666667 and parameters: {'init_lr': 0.0018943908489336672, 'gamma': 0.6516712821534072, 'batch_size': 32}. Best is trial 8 with value: 0.9135833333333333.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.909\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:12:54,084]\u001B[0m Trial 15 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.853\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:13:00,850]\u001B[0m Trial 16 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.873\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:13:14,961]\u001B[0m Trial 17 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.768\n",
      "epoch 1 of 5: val_acc: 0.874\n",
      "epoch 2 of 5: val_acc: 0.894\n",
      "epoch 3 of 5: val_acc: 0.902\n",
      "epoch 4 of 5: val_acc: 0.905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:14:00,579]\u001B[0m Trial 18 finished with value: 0.9088333333333334 and parameters: {'init_lr': 0.014133941194170468, 'gamma': 0.66337319348363, 'batch_size': 32}. Best is trial 8 with value: 0.9135833333333333.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.909\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:14:06,029]\u001B[0m Trial 19 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.854\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:14:15,213]\u001B[0m Trial 20 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.856\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:14:29,256]\u001B[0m Trial 21 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.868\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:14:43,310]\u001B[0m Trial 22 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.872\n",
      "epoch 1 of 5: val_acc: 0.881\n",
      "epoch 2 of 5: val_acc: 0.892\n",
      "epoch 3 of 5: val_acc: 0.902\n",
      "epoch 4 of 5: val_acc: 0.906\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:15:53,487]\u001B[0m Trial 23 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.908\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:16:07,585]\u001B[0m Trial 24 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.871\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:16:21,513]\u001B[0m Trial 25 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.862\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:16:27,041]\u001B[0m Trial 26 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.871\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:16:33,860]\u001B[0m Trial 27 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.862\n",
      "epoch 1 of 5: val_acc: 0.881\n",
      "epoch 2 of 5: val_acc: 0.895\n",
      "epoch 3 of 5: val_acc: 0.902\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:17:10,656]\u001B[0m Trial 28 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4 of 5: val_acc: 0.904\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:17:16,309]\u001B[0m Trial 29 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.862\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:17:30,356]\u001B[0m Trial 30 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.844\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:17:39,507]\u001B[0m Trial 31 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.862\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:17:48,824]\u001B[0m Trial 32 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.864\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:17:57,955]\u001B[0m Trial 33 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.863\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:18:07,134]\u001B[0m Trial 34 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.844\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:18:12,678]\u001B[0m Trial 35 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.856\n",
      "epoch 1 of 5: val_acc: 0.879\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:18:26,426]\u001B[0m Trial 36 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 of 5: val_acc: 0.884\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:18:31,971]\u001B[0m Trial 37 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.821\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:18:41,220]\u001B[0m Trial 38 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.854\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:18:46,811]\u001B[0m Trial 39 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.850\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:18:56,042]\u001B[0m Trial 40 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.868\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:19:05,226]\u001B[0m Trial 41 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.865\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:19:14,346]\u001B[0m Trial 42 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.846\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:19:23,568]\u001B[0m Trial 43 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.861\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:19:32,751]\u001B[0m Trial 44 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.850\n",
      "epoch 1 of 5: val_acc: 0.877\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:19:50,938]\u001B[0m Trial 45 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 of 5: val_acc: 0.880\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:19:57,719]\u001B[0m Trial 46 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.864\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:20:03,106]\u001B[0m Trial 47 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.869\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:20:12,281]\u001B[0m Trial 48 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.870\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:20:26,233]\u001B[0m Trial 49 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.804\n",
      "epoch 1 of 5: val_acc: 0.883\n",
      "epoch 2 of 5: val_acc: 0.898\n",
      "epoch 3 of 5: val_acc: 0.908\n",
      "epoch 4 of 5: val_acc: 0.904\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:21:12,202]\u001B[0m Trial 50 finished with value: 0.91525 and parameters: {'init_lr': 0.001380615733475873, 'gamma': 0.6750421181937485, 'batch_size': 32}. Best is trial 50 with value: 0.91525.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.915\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:21:21,381]\u001B[0m Trial 51 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.871\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:21:30,646]\u001B[0m Trial 52 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.869\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:21:39,823]\u001B[0m Trial 53 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.868\n",
      "epoch 1 of 5: val_acc: 0.882\n",
      "epoch 2 of 5: val_acc: 0.897\n",
      "epoch 3 of 5: val_acc: 0.903\n",
      "epoch 4 of 5: val_acc: 0.905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:22:25,508]\u001B[0m Trial 54 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.907\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:22:39,637]\u001B[0m Trial 55 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.862\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:22:45,128]\u001B[0m Trial 56 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.828\n",
      "epoch 1 of 5: val_acc: 0.879\n",
      "epoch 2 of 5: val_acc: 0.895\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:23:12,587]\u001B[0m Trial 57 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 of 5: val_acc: 0.899\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:23:26,605]\u001B[0m Trial 58 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.866\n",
      "epoch 1 of 5: val_acc: 0.892\n",
      "epoch 2 of 5: val_acc: 0.891\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:23:54,250]\u001B[0m Trial 59 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 of 5: val_acc: 0.899\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:24:01,135]\u001B[0m Trial 60 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.863\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:24:06,580]\u001B[0m Trial 61 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.834\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:24:12,093]\u001B[0m Trial 62 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.866\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:24:17,624]\u001B[0m Trial 63 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.861\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:24:23,021]\u001B[0m Trial 64 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.868\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:24:37,303]\u001B[0m Trial 65 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.839\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:24:42,840]\u001B[0m Trial 66 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.812\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:24:51,987]\u001B[0m Trial 67 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.870\n",
      "epoch 1 of 5: val_acc: 0.878\n",
      "epoch 2 of 5: val_acc: 0.891\n",
      "epoch 3 of 5: val_acc: 0.902\n",
      "epoch 4 of 5: val_acc: 0.905\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:26:02,042]\u001B[0m Trial 68 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 of 5: val_acc: 0.906\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:26:07,605]\u001B[0m Trial 69 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.854\n",
      "epoch 1 of 5: val_acc: 0.876\n",
      "epoch 2 of 5: val_acc: 0.889\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:26:35,152]\u001B[0m Trial 70 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 of 5: val_acc: 0.892\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:26:41,848]\u001B[0m Trial 71 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.870\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:26:48,585]\u001B[0m Trial 72 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.873\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:26:55,376]\u001B[0m Trial 73 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.848\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:27:02,053]\u001B[0m Trial 74 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.870\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:27:11,261]\u001B[0m Trial 75 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.874\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:27:17,920]\u001B[0m Trial 76 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.869\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:27:23,525]\u001B[0m Trial 77 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.860\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:27:32,749]\u001B[0m Trial 78 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.858\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:27:46,814]\u001B[0m Trial 79 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.845\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:27:55,908]\u001B[0m Trial 80 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.875\n",
      "epoch 1 of 5: val_acc: 0.886\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:28:14,318]\u001B[0m Trial 81 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 of 5: val_acc: 0.885\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:28:23,514]\u001B[0m Trial 82 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.763\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:28:32,757]\u001B[0m Trial 83 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.841\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:28:41,868]\u001B[0m Trial 84 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.805\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:28:51,067]\u001B[0m Trial 85 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.838\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:28:56,577]\u001B[0m Trial 86 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.820\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:29:05,849]\u001B[0m Trial 87 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.863\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:29:20,141]\u001B[0m Trial 88 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.855\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:29:26,862]\u001B[0m Trial 89 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.857\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:29:36,094]\u001B[0m Trial 90 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.867\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:29:41,522]\u001B[0m Trial 91 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.753\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:29:47,010]\u001B[0m Trial 92 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.777\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:29:52,635]\u001B[0m Trial 93 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.740\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:29:58,148]\u001B[0m Trial 94 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.843\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:30:03,739]\u001B[0m Trial 95 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.805\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:30:13,002]\u001B[0m Trial 96 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.734\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:30:27,115]\u001B[0m Trial 97 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.869\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:30:32,712]\u001B[0m Trial 98 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.758\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[32m[I 2022-04-20 04:30:41,837]\u001B[0m Trial 99 pruned. \u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 of 5: val_acc: 0.873\n",
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  90\n",
      "  Number of complete trials:  10\n",
      "Best trial:\n",
      "  Value:  0.91525\n",
      "  Params: \n",
      "    init_lr: 0.001380615733475873\n",
      "    gamma: 0.6750421181937485\n",
      "    batch_size: 32\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "A0FsTwNGJglK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}